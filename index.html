<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ollama Zephyr 7B</title>
    <link rel="stylesheet" href="style.css">
</head>

<body>
    <h1>Chat with Zephyr</h1>
    <p>This is a local implementation of the <a href="https://huggingface.co/HuggingFaceH4/zephyr-7b-beta" target="_blank">Zephyr 7B Model</a><br>
        Zephyr in turn is an improvement of the Mistral 7B model by <a href="https://mistral.ai/" target="_blank">Mistral AI</a>.<br>
        The model (as well as the Mistral model) is released under the Apache 2.0 license</p>
    <p>The model runs locally on a computer in F3, and I'm not logging anything.</p>
    <p>If there is a problem with the implementation, contact bistromd@arcada.fi<br>
        If you want to contribute you can find the code <a href="https://github.com/arcada-uas/TechLabs-ZephyrChat" target="_blank">here</a></p>
    <input id="query" type="text" size="50">
    <button id="send">Send</button>
    <p id="question"></p>
    <p id="out">
    </p>
    <p>Made with love by Dennis B <br>
        Wanna try or compare LLMs?<br>Head on over to <a href="https://arena.lmsys.org/" target="_blank">https://arena.lmsys.org/</a></p>
</body>

</html>
<script>
    async function sendQuery() {
        // Grab query from input box
        const query = document.querySelector("#query").value;
        document.querySelector("#question").innerText = "LOADING..."; // Empty response box before next response
        // console.log("Query:" + query); // Debug
        // Send message to API
        const response = await fetch("http://193.167.37.245:11434/api/generate", {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ "model": "zephyr", "prompt": query })
        });

        // Iterate response.body (a ReadableStream) asynchronously
        const chunks = [];
        for await (const chunk of response.body) {
            // Empty response box as soon as first chunk arrives.
            if (document.querySelector("#question").innerText == "LOADING...") {
                document.querySelector("#question").innerText = "Query: " + query;
                document.querySelector("#out").innerText = "Reply: ";
            } 
            // Do something with each chunk
            let res = await new Response(chunk).text() // Uint8Array stream to text through Response Obj          
            res = "[" + res + "]"; // Reformat bad json output of model
            res = res.replace('"\n"', "<br>");  // Model outputs newlines, turn them into html breaks.
            res = res.replaceAll("\n", ","); // Find newlines that ollama adds at the end of each line of json, remove them
            res = res.replace("},]", "}]"); // Remove comma from final object in multiple lines of objects
            resJson = JSON.parse(res); // Parse model output into json array of objects
            resJson.forEach(element => {
                // console.log(element.response); // Debug
                document.querySelector("#out").innerText += element.response; // Add response to html
            });             
        }
    }
    // Listen for klick on send button or enter key
    document.querySelector("#send").addEventListener("click", sendQuery);
    document.querySelector("#query").addEventListener("keydown", function (e) { if (13 == e.keyCode) { sendQuery() } });
</script>
